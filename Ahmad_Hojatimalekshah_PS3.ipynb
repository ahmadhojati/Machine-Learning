{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahmad Hojatimalekshah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborate: Arash Modaresi, Amir Kazemzadeh, Ali Nazari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS534 Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split , StratifiedKFold,KFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "y[y == 2]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting train and test\n",
    "\n",
    "We will split the training data to train and validation in the main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the parameters grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C, gamma and degree space\n",
    "c = np.array([0.01,0.1,1,10])\n",
    "g = np.array([0.0001,0.001,0.01,0.1,1])\n",
    "d = np.array([1,2,3,4,5])\n",
    "\n",
    "# Meshgrid of the parameters\n",
    "cv, gv, dv = np.meshgrid(c,g, d)\n",
    "\n",
    "# All parameters in different columns\n",
    "parm = np.concatenate((cv.reshape((len(c)*len(g)*len(d),1)),gv.reshape((len(c)*len(g)*len(d),1)),dv.reshape((len(c)*len(g)*len(d),1))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Classifiers and their accuracy\n",
    "#### We use K-fold cross validation with number of splits equal n_splits\n",
    "#### We also standardize train and tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_splits : number of splits for K-Fold cross validation\n",
    "- ind : list of test and train index splitted by K-Fold\n",
    "- df2 : mean of accuracy for folds\n",
    "- X_train_std: standardized train features\n",
    "- X_test_std: standardized test features\n",
    "- X_validation: standardized validation features\n",
    "- X_polyf_train: transformed training data\n",
    "- X_polyf_valid: transformed validation data\n",
    "- y_train: train targets (0,1)\n",
    "- y_test: test targets (0,1)\n",
    "- y_validation: validation targets (0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for inner k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_(n_splits,X,y,parm):\n",
    "    \n",
    "    # Defining a K-Fold cross validation\n",
    "    skf = KFold(n_splits=n_splits,random_state=1234,shuffle=True )\n",
    "\n",
    "    # Train and validation data index\n",
    "    ind = list(skf.split(X, y))\n",
    "\n",
    "    # Empty DataFrame for results\n",
    "    df = pd.DataFrame(columns=['C','gamma','degree','rbf','poly',\n",
    "                                    'linear'])\n",
    "\n",
    "    # loop over length of the parameters and different folds\n",
    "    for i in range(len(parm)):\n",
    "\n",
    "        # Creating different classifiers\n",
    "        clf_rbf = SVC(kernel='rbf', C=parm[i][0], gamma=parm[i][1])\n",
    "        clf_poly = SVC(kernel='poly', C=parm[i][0], gamma=parm[i][1], degree = parm[i][2])\n",
    "        clf_polyf = SVC(kernel='linear', C=parm[i][0], gamma=parm[i][1])\n",
    "\n",
    "        # model for transfering the data to polynomial\n",
    "        poly = PolynomialFeatures(degree =  (parm[i][2]).astype(int))\n",
    "        \n",
    "        # Empty DataFrame for results\n",
    "        df1 = pd.DataFrame()\n",
    "\n",
    "        # Loop over the folds\n",
    "        for j in range(0,n_splits):\n",
    "\n",
    "            # Train and validation data for each fold\n",
    "            X_train = X[ind[j][0]]\n",
    "            y_train = y[ind[j][0]]\n",
    "            X_valid = X[ind[j][1]]\n",
    "            y_valid = y[ind[j][1]]\n",
    "\n",
    "            # train and validation for polynomial features\n",
    "            X_polyf_train = poly.fit_transform(X[ind[j][0]])\n",
    "            X_polyf_valid = poly.fit_transform(X[ind[j][1]])\n",
    "\n",
    "            # Standardize the train and validation data\n",
    "            sc = StandardScaler()\n",
    "            X_train_std = sc.fit_transform(X_train)\n",
    "            X_valid_std = sc.transform(X_valid)\n",
    "            X_polyf_train_std = sc.fit_transform(X_polyf_train)\n",
    "            X_polyf_valid_std = sc.transform(X_polyf_valid)\n",
    "\n",
    "            # Fitting the classifiers\n",
    "            clf_rbf.fit(X_train_std, y_train)\n",
    "            clf_poly.fit(X_train_std, y_train)\n",
    "            clf_polyf.fit(X_polyf_train_std, y_train)\n",
    "\n",
    "            # validation accuracy\n",
    "            acc_rbf = clf_rbf.score(X_valid_std, y_valid)\n",
    "            acc_poly = clf_poly.score(X_valid_std, y_valid)\n",
    "            acc_polyf = clf_polyf.score(X_polyf_valid_std, y_valid)\n",
    "\n",
    "\n",
    "            # Appending the output of each inner fold\n",
    "            df1 = df1.append(pd.DataFrame([parm[i][0], parm[i][1],parm[i][2],acc_rbf,acc_poly,acc_polyf]),ignore_index=True)\n",
    "        # mean of the inner folds\n",
    "        df2 = np.mean(df1,axis=1)\n",
    "        \n",
    "        # parameters with validation accuracy\n",
    "        df = df.append({'C':df2[0],'gamma':df2[1],'degree':df2[2],'rbf':df2[3],\n",
    "                        'poly':df2[4],'linear':df2[5]},\n",
    "                       ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of splits for K-Fold cross validation\n",
    "n_splits= 3           # number of folds for inner k-fold\n",
    "outer_fold_num = 5    # number of folds for outer k-fold\n",
    "\n",
    "# Defining a K-Fold cross validation\n",
    "skf = KFold(n_splits=outer_fold_num,random_state=1234,shuffle=True )\n",
    "\n",
    "# Train and validation data index\n",
    "ind = list(skf.split(X, y))\n",
    "\n",
    "# defime emty dataframe for saving the results\n",
    "df_output = pd.DataFrame()\n",
    "df_result = pd.DataFrame(columns=['kernel','C','gamma','degree','accuracy'])\n",
    "\n",
    "# Outer k-fold cross validation\n",
    "for i in range(0,outer_fold_num):\n",
    "    \n",
    "    # Train and validation data for each fold\n",
    "    X_train = X[ind[i][0]]\n",
    "    y_train = y[ind[i][0]]\n",
    "    X_valid = X[ind[i][1]]\n",
    "    y_valid = y[ind[i][1]]\n",
    "\n",
    "    # inner k-fold cross validation result\n",
    "    df = acc_(n_splits,X_train,y_train,parm)\n",
    "    \n",
    "    # find the maximum accuracy of inner k-fold cross validation\n",
    "    df_cols = df[['rbf','poly','linear']]\n",
    "    row = max(df_cols.idxmax())\n",
    "    culmn = df_cols.max()[df_cols.max() == df_cols.max(axis=1).max()].index\n",
    "\n",
    "    # look for the kernels within the optimum parameters\n",
    "    if culmn[0]=='rbf':\n",
    "        clf = SVC(kernel=culmn[0], C=df.iloc[row,0], gamma=df.iloc[row,1])\n",
    "    elif culmn[0]=='poly':\n",
    "        clf = SVC(kernel=culmn[0], C=df.iloc[row,0], gamma=df.iloc[row,1], degree = df.iloc[row,2])\n",
    "    else: \n",
    "        clf = SVC(kernel=culmn[0], C=df.iloc[row,0], gamma=df.iloc[row,1])\n",
    "        \n",
    "        # transform the data to polynomial according to the degree\n",
    "        poly = PolynomialFeatures(degree = df.iloc[row,2].astype(int))\n",
    "        X_train = poly.fit_transform(X[ind[i][0]])\n",
    "        X_valid = poly.fit_transform(X[ind[i][1]])\n",
    "        \n",
    "    # Standardize the train and validation data\n",
    "    sc = StandardScaler()\n",
    "    X_train_std = sc.fit_transform(X_train)\n",
    "    X_valid_std = sc.transform(X_valid)\n",
    "\n",
    "    # Fitting the classifiers\n",
    "    clf.fit(X_train_std, y_train)\n",
    "\n",
    "    # validation accuracy\n",
    "    acc_rbf = clf.score(X_valid_std, y_valid)\n",
    "    \n",
    "    # append the model parameters and accuracy for each fold\n",
    "    df_result = df_result.append({'kernel':culmn[0],'C':df.iloc[row,0],'gamma':df.iloc[row,1],\n",
    "                                  'degree':df.iloc[row,2], 'accuracy':acc_rbf},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The optimum parameters and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = df_result['accuracy']\n",
    "M = df_result.iloc[df_col.idxmax(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see the prediction for the test dataset by the best classifier and the optimum parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X)\n",
    "X_test_std = sc.transform(X_test)\n",
    "# \n",
    "clf = SVC(kernel=M[0],C=M[1], gamma=M[2],degree=M[3])\n",
    "clf.fit(X_train_std, y)\n",
    "\n",
    "# test accuracy\n",
    "clf.score(X_test_std, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
